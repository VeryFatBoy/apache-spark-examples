{"cells":[{"attachments":{},"cell_type":"markdown","id":"0cd3122a-d5b8-4ad7-88d4-acb0d297e94a","metadata":{"language":"python"},"source":"<img src = \"https://github.com/VeryFatBoy/notebooks/blob/main/common/images/img_github_singlestore-jupyter_featured_2.png?raw=true\">"},{"attachments":{},"cell_type":"markdown","id":"56477740-ea4f-47ac-a1c3-3cc9ccc08a55","metadata":{"language":"python"},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/browser.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Using Apache Spark with SingleStore Notebooks</h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":4,"id":"8fe3d8c7-739f-418c-9f2b-eab712875a4b","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:21:59.825986Z","iopub.status.busy":"2024-12-21T03:21:59.825641Z","iopub.status.idle":"2024-12-21T03:22:02.169000Z","shell.execute_reply":"2024-12-21T03:22:02.167133Z","shell.execute_reply.started":"2024-12-21T03:21:59.825954Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip cache purge --quiet"},{"cell_type":"code","execution_count":5,"id":"8ab8648b-b68e-4a75-b384-84b3622a3d2a","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:22:03.363965Z","iopub.status.busy":"2024-12-21T03:22:03.363363Z","iopub.status.idle":"2024-12-21T03:22:32.530216Z","shell.execute_reply":"2024-12-21T03:22:32.529000Z","shell.execute_reply.started":"2024-12-21T03:22:03.363928Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Channels:\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - openjdk=8\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.12.14 |       hbcca054_0         153 KB  conda-forge\n    certifi-2024.12.14         |     pyhd8ed1ab_0         158 KB  conda-forge\n    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n    openjdk-8.0.412            |       hd590300_1        88.3 MB  conda-forge\n    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        92.7 MB\n\nThe following NEW packages will be INSTALLED:\n\n  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n  openjdk            conda-forge/linux-64::openjdk-8.0.412-hd590300_1 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.12.14-hbcca054_0 \n  certifi                             2024.2.2-pyhd8ed1ab_0 --> 2024.12.14-pyhd8ed1ab_0 \n  libgcc-ng                               13.2.0-h77fa898_6 --> 14.2.0-h69a702a_1 \n  libgomp                                 13.2.0-h77fa898_6 --> 14.2.0-h77fa898_1 \n  openssl                                  3.3.0-hd590300_0 --> 3.4.0-hb9d3cd8_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n"}],"source":"!conda install -y --quiet -c conda-forge openjdk=8"},{"cell_type":"code","execution_count":6,"id":"759a6a24-cb6e-4186-ba81-f376e8d4966c","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:22:37.439680Z","iopub.status.busy":"2024-12-21T03:22:37.439253Z","iopub.status.idle":"2024-12-21T03:23:05.883259Z","shell.execute_reply":"2024-12-21T03:23:05.882284Z","shell.execute_reply.started":"2024-12-21T03:22:37.439651Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install pyspark --quiet"},{"cell_type":"code","execution_count":9,"id":"285dd44c-4c59-4561-8c61-773edbd824d8","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:09.052286Z","iopub.status.busy":"2024-12-21T03:23:09.051999Z","iopub.status.idle":"2024-12-21T03:23:09.099508Z","shell.execute_reply":"2024-12-21T03:23:09.098943Z","shell.execute_reply.started":"2024-12-21T03:23:09.052262Z"},"language":"python","trusted":true},"outputs":[],"source":"import pyspark\nimport sys\n\nfrom pyspark.sql import SparkSession"},{"cell_type":"code","execution_count":10,"id":"bd8419fd-cd96-4744-b512-d6c80c826a6b","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:11.022120Z","iopub.status.busy":"2024-12-21T03:23:11.021759Z","iopub.status.idle":"2024-12-21T03:23:12.915507Z","shell.execute_reply":"2024-12-21T03:23:12.907751Z","shell.execute_reply.started":"2024-12-21T03:23:11.022085Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"openjdk version \"1.8.0_412\"\nOpenJDK Runtime Environment (Zulu 8.78.0.19-CA-linux64) (build 1.8.0_412-b08)\nOpenJDK 64-Bit Server VM (Zulu 8.78.0.19-CA-linux64) (build 25.412-b08, mixed mode)\n"}],"source":"!java -version"},{"cell_type":"code","execution_count":11,"id":"5f5892fc-d8b0-4a32-bfaa-153df57ec108","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:14.894231Z","iopub.status.busy":"2024-12-21T03:23:14.893664Z","iopub.status.idle":"2024-12-21T03:23:14.900476Z","shell.execute_reply":"2024-12-21T03:23:14.899829Z","shell.execute_reply.started":"2024-12-21T03:23:14.894196Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3.5.4\n"}],"source":"print(pyspark.__version__)"},{"cell_type":"code","execution_count":12,"id":"ea1df563-0b4f-48f8-9951-c8653d8bec6c","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:17.295516Z","iopub.status.busy":"2024-12-21T03:23:17.295139Z","iopub.status.idle":"2024-12-21T03:23:17.300672Z","shell.execute_reply":"2024-12-21T03:23:17.300142Z","shell.execute_reply.started":"2024-12-21T03:23:17.295482Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]\n"}],"source":"print(sys.version)"},{"cell_type":"code","execution_count":13,"id":"1e4265c2-f968-4f9b-8a20-6d8da36c16d3","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:20.048464Z","iopub.status.busy":"2024-12-21T03:23:20.047958Z","iopub.status.idle":"2024-12-21T03:23:25.022814Z","shell.execute_reply":"2024-12-21T03:23:25.019259Z","shell.execute_reply.started":"2024-12-21T03:23:20.048425Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/12/21 03:23:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"}],"source":"# Create a Spark session\nspark = SparkSession.builder.appName(\"Spark Test\").getOrCreate()"},{"cell_type":"code","execution_count":14,"id":"927db2dd-7746-4cfd-9590-e69c790fb20e","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:26.365212Z","iopub.status.busy":"2024-12-21T03:23:26.364750Z","iopub.status.idle":"2024-12-21T03:23:28.999671Z","shell.execute_reply":"2024-12-21T03:23:28.999147Z","shell.execute_reply.started":"2024-12-21T03:23:26.365178Z"},"language":"python","trusted":true},"outputs":[],"source":"# Create a DataFrame\ndata = [(\"Peter\", 27), (\"Paul\", 28), (\"Mary\", 29)]\ndf = spark.createDataFrame(data, [\"Name\", \"Age\"])"},{"cell_type":"code","execution_count":15,"id":"a58a70a7-86bf-44e4-b8fb-1f0838e57929","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:30.109044Z","iopub.status.busy":"2024-12-21T03:23:30.108701Z","iopub.status.idle":"2024-12-21T03:23:34.879104Z","shell.execute_reply":"2024-12-21T03:23:34.877151Z","shell.execute_reply.started":"2024-12-21T03:23:30.109016Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"                                                                                \r"},{"name":"stdout","output_type":"stream","text":"+-----+---+\n| Name|Age|\n+-----+---+\n|Peter| 27|\n| Paul| 28|\n| Mary| 29|\n+-----+---+\n\n"}],"source":"# Show the content of the DataFrame\ndf.show()"},{"cell_type":"code","execution_count":16,"id":"d52a9777-83df-4f1d-a325-8f2c39043db4","metadata":{"execution":{"iopub.execute_input":"2024-12-21T03:23:37.193431Z","iopub.status.busy":"2024-12-21T03:23:37.192846Z","iopub.status.idle":"2024-12-21T03:23:37.542113Z","shell.execute_reply":"2024-12-21T03:23:37.541204Z","shell.execute_reply.started":"2024-12-21T03:23:37.193391Z"},"language":"python","trusted":true},"outputs":[],"source":"# Stop the Spark session\nspark.stop()"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"ee3b81d3-c349-4926-bd4b-6784b6bb2d9c","defaultDatabase":""},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}