{"cells":[{"attachments":{},"cell_type":"markdown","id":"b52452b1-90e7-4e77-a4aa-4109c5fb79c4","metadata":{"language":"python"},"source":"<img src = \"https://github.com/VeryFatBoy/notebooks/blob/main/common/images/img_github_singlestore-jupyter_featured_2.png?raw=true\">"},{"attachments":{},"cell_type":"markdown","id":"e83a3630-3c94-4bc6-ab80-18563b926388","metadata":{"language":"python"},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/browser.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Using Apache Spark Structured Streaming with SingleStore Notebooks</h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":7,"id":"b7977218-34bb-4ed1-98b2-29046761bd21","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:30:57.826479Z","iopub.status.busy":"2024-12-18T11:30:57.826061Z","iopub.status.idle":"2024-12-18T11:31:00.342036Z","shell.execute_reply":"2024-12-18T11:31:00.294837Z","shell.execute_reply.started":"2024-12-18T11:30:57.826437Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip cache purge --quiet"},{"cell_type":"code","execution_count":8,"id":"4aed2148-2b94-4eb0-95e1-dd6e9a2b3dc9","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:31:02.135391Z","iopub.status.busy":"2024-12-18T11:31:02.134628Z","iopub.status.idle":"2024-12-18T11:31:59.779547Z","shell.execute_reply":"2024-12-18T11:31:59.758607Z","shell.execute_reply.started":"2024-12-18T11:31:02.135354Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Channels:\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - openjdk=11\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    alsa-lib-1.2.13            |       hb9d3cd8_0         547 KB  conda-forge\n    ca-certificates-2024.12.14 |       hbcca054_0         153 KB  conda-forge\n    cairo-1.18.2               |       h3394656_1         956 KB  conda-forge\n    certifi-2024.12.14         |     pyhd8ed1ab_0         158 KB  conda-forge\n    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n    fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge\n    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n    fonts-conda-forge-1        |                0           4 KB  conda-forge\n    freetype-2.12.1            |       h267a509_2         620 KB  conda-forge\n    giflib-5.2.2               |       hd590300_0          75 KB  conda-forge\n    graphite2-1.3.13           |    h59595ed_1003          95 KB  conda-forge\n    harfbuzz-10.1.0            |       h0b3b770_0         1.5 MB  conda-forge\n    icu-75.1                   |       he02047a_0        11.6 MB  conda-forge\n    lcms2-2.16                 |       hb7c19ff_0         239 KB  conda-forge\n    lerc-4.0.0                 |       h27087fc_0         275 KB  conda-forge\n    libarchive-3.7.2           |       h039dbb9_0         846 KB  conda-forge\n    libcups-2.3.3              |       h4637d8d_4         4.3 MB  conda-forge\n    libcurl-8.6.0              |       hca28451_0         382 KB  conda-forge\n    libdeflate-1.20            |       hd590300_0          70 KB  conda-forge\n    libexpat-2.6.4             |       h5888daf_0          72 KB  conda-forge\n    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n    libglib-2.82.2             |       h2ff4ddf_0         3.7 MB  conda-forge\n    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n    libjpeg-turbo-3.0.0        |       hd590300_1         604 KB  conda-forge\n    liblzma-5.6.3              |       hb9d3cd8_1         109 KB  conda-forge\n    libnghttp2-1.58.0          |       h47da74e_0         617 KB  conda-forge\n    libpng-1.6.44              |       hadc24fc_0         284 KB  conda-forge\n    libsolv-0.7.30             |       h3509ff9_0         460 KB  conda-forge\n    libsqlite-3.47.2           |       hee588c1_0         853 KB  conda-forge\n    libssh2-1.11.1             |       hf672d98_0         297 KB  conda-forge\n    libstdcxx-14.2.0           |       hc0a3c3a_1         3.7 MB  conda-forge\n    libtiff-4.6.0              |       h1dd3fc0_3         276 KB  conda-forge\n    libwebp-base-1.4.0         |       hd590300_0         429 KB  conda-forge\n    libxcb-1.17.0              |       h8a09558_0         387 KB  conda-forge\n    libxml2-2.13.5             |       h8d12d68_1         674 KB  conda-forge\n    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n    nodejs-20.17.0             |       hc55a1b2_0        16.4 MB  conda-forge\n    openjdk-11.0.25            |       he4ca013_1       164.0 MB  conda-forge\n    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n    pcre2-10.44                |       hba22ea6_2         930 KB  conda-forge\n    pixman-0.44.2              |       h29eaf8c_0         372 KB  conda-forge\n    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n    python-3.11.11             |h9e4cc4f_1_cpython        29.2 MB  conda-forge\n    tk-8.6.13                  |       h2797004_0         3.1 MB  conda-forge\n    xorg-libice-1.1.2          |       hb9d3cd8_0          57 KB  conda-forge\n    xorg-libsm-1.2.5           |       he73a12e_0          27 KB  conda-forge\n    xorg-libx11-1.8.10         |       h4f16b4b_1         818 KB  conda-forge\n    xorg-libxau-1.0.12         |       hb9d3cd8_0          14 KB  conda-forge\n    xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge\n    xorg-libxext-1.3.6         |       hb9d3cd8_0          49 KB  conda-forge\n    xorg-libxfixes-6.0.1       |       hb9d3cd8_0          19 KB  conda-forge\n    xorg-libxi-1.8.2           |       hb9d3cd8_0          46 KB  conda-forge\n    xorg-libxrandr-1.5.4       |       hb9d3cd8_0          29 KB  conda-forge\n    xorg-libxrender-0.9.12     |       hb9d3cd8_0          32 KB  conda-forge\n    xorg-libxt-1.3.1           |       hb9d3cd8_0         371 KB  conda-forge\n    xorg-libxtst-1.2.5         |       hb9d3cd8_3          32 KB  conda-forge\n    zlib-1.3.1                 |       hb9d3cd8_2          90 KB  conda-forge\n    zstd-1.5.5                 |       hfc55251_0         532 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:       258.2 MB\n\nThe following NEW packages will be INSTALLED:\n\n  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.13-hb9d3cd8_0 \n  cairo              conda-forge/linux-64::cairo-1.18.2-h3394656_1 \n  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n  freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 \n  giflib             conda-forge/linux-64::giflib-5.2.2-hd590300_0 \n  graphite2          conda-forge/linux-64::graphite2-1.3.13-h59595ed_1003 \n  harfbuzz           conda-forge/linux-64::harfbuzz-10.1.0-h0b3b770_0 \n  lcms2              conda-forge/linux-64::lcms2-2.16-hb7c19ff_0 \n  lerc               conda-forge/linux-64::lerc-4.0.0-h27087fc_0 \n  libcups            conda-forge/linux-64::libcups-2.3.3-h4637d8d_4 \n  libdeflate         conda-forge/linux-64::libdeflate-1.20-hd590300_0 \n  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n  libglib            conda-forge/linux-64::libglib-2.82.2-h2ff4ddf_0 \n  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.0.0-hd590300_1 \n  liblzma            conda-forge/linux-64::liblzma-5.6.3-hb9d3cd8_1 \n  libpng             conda-forge/linux-64::libpng-1.6.44-hadc24fc_0 \n  libstdcxx          conda-forge/linux-64::libstdcxx-14.2.0-hc0a3c3a_1 \n  libtiff            conda-forge/linux-64::libtiff-4.6.0-h1dd3fc0_3 \n  libwebp-base       conda-forge/linux-64::libwebp-base-1.4.0-hd590300_0 \n  libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 \n  openjdk            conda-forge/linux-64::openjdk-11.0.25-he4ca013_1 \n  pcre2              conda-forge/linux-64::pcre2-10.44-hba22ea6_2 \n  pixman             conda-forge/linux-64::pixman-0.44.2-h29eaf8c_0 \n  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 \n  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.5-he73a12e_0 \n  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.10-h4f16b4b_1 \n  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 \n  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.6-hb9d3cd8_0 \n  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-6.0.1-hb9d3cd8_0 \n  xorg-libxi         conda-forge/linux-64::xorg-libxi-1.8.2-hb9d3cd8_0 \n  xorg-libxrandr     conda-forge/linux-64::xorg-libxrandr-1.5.4-hb9d3cd8_0 \n  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.12-hb9d3cd8_0 \n  xorg-libxt         conda-forge/linux-64::xorg-libxt-1.3.1-hb9d3cd8_0 \n  xorg-libxtst       conda-forge/linux-64::xorg-libxtst-1.2.5-hb9d3cd8_3 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.12.14-hbcca054_0 \n  certifi                             2024.2.2-pyhd8ed1ab_0 --> 2024.12.14-pyhd8ed1ab_0 \n  icu                                       73.2-h59595ed_0 --> 75.1-he02047a_0 \n  libexpat                                 2.6.2-h59595ed_0 --> 2.6.4-h5888daf_0 \n  libgcc-ng                               13.2.0-h77fa898_6 --> 14.2.0-h69a702a_1 \n  libgomp                                 13.2.0-h77fa898_6 --> 14.2.0-h77fa898_1 \n  libsolv                                 0.7.29-ha6fb4c9_0 --> 0.7.30-h3509ff9_0 \n  libsqlite                               3.45.3-h2797004_0 --> 3.47.2-hee588c1_0 \n  libssh2                                 1.11.0-h0841786_0 --> 1.11.1-hf672d98_0 \n  libxml2                                 2.12.6-h232c23b_2 --> 2.13.5-h8d12d68_1 \n  libzlib                                 1.2.13-hd590300_5 --> 1.3.1-hb9d3cd8_2 \n  ncurses                           6.4.20240210-h59595ed_0 --> 6.5-he02047a_1 \n  nodejs                                 20.12.2-hb753e55_0 --> 20.17.0-hc55a1b2_0 \n  openssl                                  3.3.0-hd590300_0 --> 3.4.0-hb9d3cd8_0 \n  python                          3.11.9-hb806964_0_cpython --> 3.11.11-h9e4cc4f_1_cpython \n  zlib                                    1.2.13-hd590300_5 --> 1.3.1-hb9d3cd8_2 \n\nThe following packages will be DOWNGRADED:\n\n  libarchive                               3.7.2-h2aa1ff5_1 --> 3.7.2-h039dbb9_0 \n  libcurl                                  8.7.1-hca28451_0 --> 8.6.0-hca28451_0 \n  libnghttp2                              1.58.0-h47da74e_1 --> 1.58.0-h47da74e_0 \n  tk                              8.6.13-noxft_h4845f30_101 --> 8.6.13-h2797004_0 \n  zstd                                     1.5.6-ha6fb4c9_0 --> 1.5.5-hfc55251_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n"}],"source":"!conda install -y --quiet -c conda-forge openjdk=11"},{"cell_type":"code","execution_count":11,"id":"7f8b6247-0e7e-4a95-832b-c116cc8192f9","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:32:06.243524Z","iopub.status.busy":"2024-12-18T11:32:06.243131Z","iopub.status.idle":"2024-12-18T11:32:59.515885Z","shell.execute_reply":"2024-12-18T11:32:59.504821Z","shell.execute_reply.started":"2024-12-18T11:32:06.243483Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install openai==0.28 --quiet\n!pip install nltk --quiet\n!pip install pyspark --quiet"},{"cell_type":"code","execution_count":12,"id":"d5139227-53b1-47cf-8339-1aa8386ec99d","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:02.742507Z","iopub.status.busy":"2024-12-18T11:33:02.741526Z","iopub.status.idle":"2024-12-18T11:33:03.608742Z","shell.execute_reply":"2024-12-18T11:33:03.607627Z","shell.execute_reply.started":"2024-12-18T11:33:02.742455Z"},"language":"python","trusted":true},"outputs":[],"source":"import getpass\nimport nltk\nimport openai\nimport os\nimport random\nimport requests\nimport shutil\nimport time\n\nfrom nltk.corpus import wordnet as wn\nfrom nltk.tokenize import word_tokenize\nfrom pathlib import Path\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import input_file_name, udf\nfrom pyspark.sql.types import StringType\nfrom singlestoredb.management import get_secret"},{"cell_type":"code","execution_count":13,"id":"c3923018-1424-4586-ad14-242ad6eafa78","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:06.201975Z","iopub.status.busy":"2024-12-18T11:33:06.201020Z","iopub.status.idle":"2024-12-18T11:33:06.834625Z","shell.execute_reply":"2024-12-18T11:33:06.834055Z","shell.execute_reply.started":"2024-12-18T11:33:06.201830Z"},"language":"python","trusted":true},"outputs":[],"source":"os.environ[\"OPENAI_API_KEY\"] = get_secret(\"OPENAI_API_KEY\")"},{"cell_type":"code","execution_count":14,"id":"a3a23d21-013d-412e-a120-4c56d9111af8","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:08.379014Z","iopub.status.busy":"2024-12-18T11:33:08.378208Z","iopub.status.idle":"2024-12-18T11:33:08.385517Z","shell.execute_reply":"2024-12-18T11:33:08.384091Z","shell.execute_reply.started":"2024-12-18T11:33:08.378977Z"},"language":"python","trusted":true},"outputs":[],"source":"os.makedirs(\"jars\", exist_ok = True)\nos.makedirs(\"data\", exist_ok = True)"},{"cell_type":"code","execution_count":15,"id":"d935b474-40a7-46ec-9ded-51cc2a572ca3","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:11.471993Z","iopub.status.busy":"2024-12-18T11:33:11.471175Z","iopub.status.idle":"2024-12-18T11:33:11.873723Z","shell.execute_reply":"2024-12-18T11:33:11.873041Z","shell.execute_reply.started":"2024-12-18T11:33:11.471734Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"JAR files downloaded successfully\n"}],"source":"def download_jar(url, destination):\n    response = requests.get(url)\n    with open(destination, \"wb\") as f:\n        f.write(response.content)\n\njar_urls = [\n    (\"https://repo1.maven.org/maven2/com/singlestore/singlestore-jdbc-client/1.2.4/singlestore-jdbc-client-1.2.4.jar\", \"jars/singlestore-jdbc-client-1.2.4.jar\"),\n    (\"https://repo1.maven.org/maven2/com/singlestore/singlestore-spark-connector_2.12/4.1.8-spark-3.5.0/singlestore-spark-connector_2.12-4.1.8-spark-3.5.0.jar\", \"jars/singlestore-spark-connector_2.12-4.1.8-spark-3.5.0.jar\"),\n    (\"https://repo1.maven.org/maven2/org/apache/commons/commons-dbcp2/2.12.0/commons-dbcp2-2.12.0.jar\", \"jars/commons-dbcp2-2.12.0.jar\"),\n    (\"https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.12.0/commons-pool2-2.12.0.jar\", \"jars/commons-pool2-2.12.0.jar\"),\n    (\"https://repo1.maven.org/maven2/io/spray/spray-json_3/1.3.6/spray-json_3-1.3.6.jar\", \"jars/spray-json_3-1.3.6.jar\")\n]\n\nfor url, destination in jar_urls:\n    download_jar(url, destination)\n\nprint(\"JAR files downloaded successfully\")"},{"cell_type":"code","execution_count":16,"id":"de40d2d2-3558-4d47-bf86-a6d766b8d5d8","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:13.254374Z","iopub.status.busy":"2024-12-18T11:33:13.252775Z","iopub.status.idle":"2024-12-18T11:33:20.406080Z","shell.execute_reply":"2024-12-18T11:33:20.404831Z","shell.execute_reply.started":"2024-12-18T11:33:13.254294Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"24/12/18 11:33:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"}],"source":"# Create a Spark session\nspark = (SparkSession\n             .builder\n             .config(\"spark.jars\", \",\".join([destination for _, destination in jar_urls]))\n             .appName(\"Spark Streaming Test\")\n             .getOrCreate()\n        )\n\nspark.sparkContext.setLogLevel(\"ERROR\")"},{"cell_type":"code","execution_count":17,"id":"58824718-81ee-4b6b-a0c0-ac07925f8ffc","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:22.896817Z","iopub.status.busy":"2024-12-18T11:33:22.896003Z","iopub.status.idle":"2024-12-18T11:33:23.347807Z","shell.execute_reply":"2024-12-18T11:33:23.347248Z","shell.execute_reply.started":"2024-12-18T11:33:22.896786Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data] Downloading package omw to /home/jovyan/nltk_data...\n"},{"data":{"text/plain":"True"},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":"# Download NLTK\nnltk.download(\"punkt_tab\")\nnltk.download(\"averaged_perceptron_tagger\")\nnltk.download(\"wordnet\")\nnltk.download(\"omw\")"},{"cell_type":"code","execution_count":18,"id":"cafc9dbb-0b3f-4054-a208-7d5a1d60e54f","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:25.924687Z","iopub.status.busy":"2024-12-18T11:33:25.923865Z","iopub.status.idle":"2024-12-18T11:33:37.807056Z","shell.execute_reply":"2024-12-18T11:33:37.806382Z","shell.execute_reply.started":"2024-12-18T11:33:25.924639Z"},"language":"python","trusted":true},"outputs":[],"source":"# Define the directory to save the files\noutput_dir = \"data\"\n\n# Generate meaningful sentences\ndef generate_meaningful_sentence():\n    # Choose a random set of synonyms from WordNet\n    synset = random.choice(list(wn.all_synsets()))\n\n    # Generate a sentence\n    definition = synset.definition()\n    tokens = word_tokenize(definition)\n\n    # Capitalise the first word and end with a period\n    tokens[0] = tokens[0].capitalize()\n    tokens[-1] = tokens[-1] + \".\"\n\n    return \" \".join(tokens)\n\n# Number of files to generate\nnum_files = 5\n\n# Number of sentences in each file\nnum_sentences_per_file = 1\n\n# Generate text files\nfor i in range(num_files):\n    file_path = os.path.join(output_dir, f\"file_{i+1}.txt\")\n    with open(file_path, \"w\") as file:\n        for _ in range(num_sentences_per_file):\n            # Generate a meaningful sentence\n            sentence = generate_meaningful_sentence()\n            file.write(sentence + \"\\n\")"},{"cell_type":"code","execution_count":19,"id":"db8ec8cb-d0e1-4bd9-bec6-fe63c9f09ba3","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:37.808536Z","iopub.status.busy":"2024-12-18T11:33:37.808302Z","iopub.status.idle":"2024-12-18T11:33:37.814478Z","shell.execute_reply":"2024-12-18T11:33:37.813971Z","shell.execute_reply.started":"2024-12-18T11:33:37.808513Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"File: data/file_1.txt\nWhip with a leather strap.\n\n----------------------\nFile: data/file_2.txt\nA receptacle for cat excrement.\n\n----------------------\nFile: data/file_3.txt\nA law that is believed to come directly from God.\n\n----------------------\nFile: data/file_4.txt\nThe localized death of living cells ( as from infection or the interruption of blood supply ).\n\n----------------------\nFile: data/file_5.txt\nDeprived of sexual capacity or sexual attributes.\n\n----------------------\n"}],"source":"# Specify the directory containing the .txt files\ndirectory = Path(\"data\")\n\n# Loop through each .txt file in the directory\nfor file_path in directory.glob(\"*.txt\"):\n    print(f\"File: {file_path}\")\n\n    # Read and print the contents of the file\n    with file_path.open() as file:\n        print(file.read())\n\n    print(\"----------------------\")"},{"cell_type":"code","execution_count":20,"id":"b676defa-6cc6-440f-b825-ad16e3986e4d","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:33:42.776338Z","iopub.status.busy":"2024-12-18T11:33:42.775961Z","iopub.status.idle":"2024-12-18T11:34:03.096812Z","shell.execute_reply":"2024-12-18T11:34:03.095257Z","shell.execute_reply.started":"2024-12-18T11:33:42.776303Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<span style=\"color: green\">1 rows affected.</span>","text/plain":"1 rows affected."},"metadata":{},"output_type":"display_data"},{"data":{"text/html":"<span style=\"color: green\">1 rows affected.</span>","text/plain":"1 rows affected."},"metadata":{},"output_type":"display_data"},{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n        </tr>\n    </thead>\n    <tbody>\n    </tbody>\n</table>","text/plain":"++\n||\n++\n++"},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nDROP DATABASE IF EXISTS spark_demo;\nCREATE DATABASE IF NOT EXISTS spark_demo;"},{"cell_type":"code","execution_count":21,"id":"65b6fc2b-427e-455f-af29-92180c12940e","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:05.193185Z","iopub.status.busy":"2024-12-18T11:34:05.191548Z","iopub.status.idle":"2024-12-18T11:34:05.406602Z","shell.execute_reply":"2024-12-18T11:34:05.403177Z","shell.execute_reply.started":"2024-12-18T11:34:05.193144Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n        </tr>\n    </thead>\n    <tbody>\n    </tbody>\n</table>","text/plain":"++\n||\n++\n++"},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nUSE spark_demo;\n\nDROP TABLE IF EXISTS streaming;\nCREATE TABLE IF NOT EXISTS streaming (\n     value TEXT,\n     file_name TEXT,\n     embedding VECTOR(1536) NOT NULL\n);"},{"attachments":{},"cell_type":"markdown","id":"f5f62a7e-0b88-4798-a42f-254c7faaa3af","metadata":{"execution":{"iopub.execute_input":"2024-09-24T15:59:27.463129Z","iopub.status.busy":"2024-09-24T15:59:27.462594Z","iopub.status.idle":"2024-09-24T15:59:27.469211Z","shell.execute_reply":"2024-09-24T15:59:27.468267Z","shell.execute_reply.started":"2024-09-24T15:59:27.463105Z"},"language":"python"},"source":"<div class=\"alert alert-block alert-warning\">\n    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n    <div>\n        <p><b>Action Required</b></p>\n        <p>Select the database from the drop-down menu at the top of this notebook. It updates the <b>connection_url</b> which is used by SQLAlchemy to make connections to the selected database.</p>\n    </div>\n</div>"},{"cell_type":"code","execution_count":24,"id":"d476668a-d48e-4db4-be37-dd0cb6d19136","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:22.936191Z","iopub.status.busy":"2024-12-18T11:34:22.935702Z","iopub.status.idle":"2024-12-18T11:34:22.946500Z","shell.execute_reply":"2024-12-18T11:34:22.943486Z","shell.execute_reply.started":"2024-12-18T11:34:22.936153Z"},"language":"python","trusted":true},"outputs":[],"source":"from sqlalchemy import *\n\ndb_connection = create_engine(connection_url)\nurl = db_connection.url"},{"cell_type":"code","execution_count":25,"id":"c861139a-cada-4d87-bee2-48b763dfbbfa","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:24.911741Z","iopub.status.busy":"2024-12-18T11:34:24.911458Z","iopub.status.idle":"2024-12-18T11:34:25.303017Z","shell.execute_reply":"2024-12-18T11:34:25.302515Z","shell.execute_reply.started":"2024-12-18T11:34:24.911718Z"},"language":"python","trusted":true},"outputs":[],"source":"password = get_secret(\"password\")\nhost = url.host\nport = url.port\ncluster = host + \":\" + str(port)"},{"cell_type":"code","execution_count":26,"id":"b4b9edb7-a883-4a4e-9ef9-a72f962cbe2d","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:26.966729Z","iopub.status.busy":"2024-12-18T11:34:26.966131Z","iopub.status.idle":"2024-12-18T11:34:27.729730Z","shell.execute_reply":"2024-12-18T11:34:27.728896Z","shell.execute_reply.started":"2024-12-18T11:34:26.966691Z"},"language":"python","trusted":true},"outputs":[],"source":"spark.conf.set(\"spark.datasource.singlestore.ddlEndpoint\", cluster)\nspark.conf.set(\"spark.datasource.singlestore.user\", \"admin\")\nspark.conf.set(\"spark.datasource.singlestore.password\", password)\nspark.conf.set(\"spark.datasource.singlestore.disablePushdown\", \"false\")"},{"cell_type":"code","execution_count":27,"id":"4aa6262d-7007-44f8-a932-c5deb8d0cfc0","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:30.122306Z","iopub.status.busy":"2024-12-18T11:34:30.121948Z","iopub.status.idle":"2024-12-18T11:34:30.127061Z","shell.execute_reply":"2024-12-18T11:34:30.126407Z","shell.execute_reply.started":"2024-12-18T11:34:30.122282Z"},"language":"python","trusted":true},"outputs":[],"source":"openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\n# Generate embeddings for text\ndef generate_embeddings(text):\n    # Generate embeddings for text using OpenAI\n    return openai.Embedding.create(\n        input = text,\n        engine = \"text-embedding-3-small\"\n    ).data[0].embedding\n\n# Register the function as a UDF\ngenerate_embeddings_udf = udf(generate_embeddings, StringType())"},{"cell_type":"code","execution_count":28,"id":"b9b0bdff-b9a1-4992-9470-fbf4a6d7d9f0","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:33.835364Z","iopub.status.busy":"2024-12-18T11:34:33.830310Z","iopub.status.idle":"2024-12-18T11:34:45.243086Z","shell.execute_reply":"2024-12-18T11:34:45.242421Z","shell.execute_reply.started":"2024-12-18T11:34:33.831515Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"                                                                                \r"}],"source":"input_dir = output_dir\n\n# Read from the directory\ndf = (spark.readStream\n    .format(\"text\")\n    .option(\"path\", input_dir)\n    .load()\n    .withColumn(\"file_name\", input_file_name())\n)\n\n# Apply the function to the DataFrame to generate embeddings for each row\ndf_with_embeddings = df.withColumn(\"embedding\", generate_embeddings_udf(\"value\"))\n\n# Write each batch of data to SingleStore\ndef write_to_singlestore(df_with_embeddings, epoch_id):\n    (df_with_embeddings.write\n         .format(\"singlestore\")\n         .option(\"loadDataCompression\", \"LZ4\")\n         .mode(\"append\")\n         .save(\"spark_demo.streaming\")\n    )\n\n# Write the streaming DataFrame to SingleStore using foreachBatch\nquery = (df_with_embeddings.writeStream\n    .foreachBatch(write_to_singlestore)\n    .start()\n)\n\n# Wait for the query to finish processing\nwhile query.isActive:\n    time.sleep(1)\n    if not query.status[\"isDataAvailable\"]:\n        query.stop()"},{"cell_type":"code","execution_count":29,"id":"a0c6b8a6-4164-44ff-9fd4-c12f14ef9219","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:34:48.940909Z","iopub.status.busy":"2024-12-18T11:34:48.940237Z","iopub.status.idle":"2024-12-18T11:34:49.225197Z","shell.execute_reply":"2024-12-18T11:34:49.224102Z","shell.execute_reply.started":"2024-12-18T11:34:48.940880Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<span style=\"color: green\">5 rows affected.</span>","text/plain":"5 rows affected."},"metadata":{},"output_type":"display_data"},{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n            <th>value</th>\n            <th>file_name</th>\n            <th>embedding</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>The localized death of living </td>\n            <td>file_4.txt</td>\n            <td>[-0.00261676731,0.0672443733,0.0220731013,0.046059</td>\n        </tr>\n        <tr>\n            <td>Whip with a leather strap.</td>\n            <td>file_1.txt</td>\n            <td>[0.0374260508,0.0438706614,-0.0315726846,0.0104946</td>\n        </tr>\n        <tr>\n            <td>Deprived of sexual capacity or</td>\n            <td>file_5.txt</td>\n            <td>[0.070780091,0.0299474057,-0.0439796112,0.05943051</td>\n        </tr>\n        <tr>\n            <td>A receptacle for cat excrement</td>\n            <td>file_2.txt</td>\n            <td>[0.0169466194,-0.0188572034,0.00297547295,0.031982</td>\n        </tr>\n        <tr>\n            <td>A law that is believed to come</td>\n            <td>file_3.txt</td>\n            <td>[0.0363025814,0.0172852241,0.0147712287,0.05167524</td>\n        </tr>\n    </tbody>\n</table>","text/plain":"+--------------------------------+------------+----------------------------------------------------+\n|             value              | file_name  |                     embedding                      |\n+--------------------------------+------------+----------------------------------------------------+\n| The localized death of living  | file_4.txt | [-0.00261676731,0.0672443733,0.0220731013,0.046059 |\n|   Whip with a leather strap.   | file_1.txt | [0.0374260508,0.0438706614,-0.0315726846,0.0104946 |\n| Deprived of sexual capacity or | file_5.txt | [0.070780091,0.0299474057,-0.0439796112,0.05943051 |\n| A receptacle for cat excrement | file_2.txt | [0.0169466194,-0.0188572034,0.00297547295,0.031982 |\n| A law that is believed to come | file_3.txt | [0.0363025814,0.0172852241,0.0147712287,0.05167524 |\n+--------------------------------+------------+----------------------------------------------------+"},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nUSE spark_demo;\n\nSELECT\n    SUBSTR(value, 1, 30) AS value,\n    SUBSTR(file_name, LENGTH(file_name) - 9) AS file_name,\n    SUBSTR(JSON_ARRAY_UNPACK(embedding :> BLOB), 1, 50) AS embedding\nFROM streaming;"},{"cell_type":"code","execution_count":30,"id":"efad259c-6c50-4cc9-aaaa-1ebd644c75e6","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:35:02.181240Z","iopub.status.busy":"2024-12-18T11:35:02.180707Z","iopub.status.idle":"2024-12-18T11:35:02.389510Z","shell.execute_reply":"2024-12-18T11:35:02.388990Z","shell.execute_reply.started":"2024-12-18T11:35:02.181208Z"},"language":"python","trusted":true},"outputs":[],"source":"spark.stop()"},{"attachments":{},"cell_type":"markdown","id":"41cc9d7a-f8f9-4e85-b01c-11237b47a378","metadata":{"language":"python"},"source":"## Cleanup"},{"cell_type":"code","execution_count":31,"id":"35a640d5-bb00-4c88-afac-18a94e1d9245","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:35:05.902238Z","iopub.status.busy":"2024-12-18T11:35:05.901710Z","iopub.status.idle":"2024-12-18T11:35:05.935646Z","shell.execute_reply":"2024-12-18T11:35:05.932141Z","shell.execute_reply.started":"2024-12-18T11:35:05.902208Z"},"language":"python","trusted":true},"outputs":[],"source":"shutil.rmtree(\"jars\")\nshutil.rmtree(\"data\")\nshutil.rmtree(\"nltk_data\")"},{"cell_type":"code","execution_count":32,"id":"39f56536-2e31-4ba2-8817-5d1a3ce64420","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:35:08.772579Z","iopub.status.busy":"2024-12-18T11:35:08.768899Z","iopub.status.idle":"2024-12-18T11:35:08.828340Z","shell.execute_reply":"2024-12-18T11:35:08.826763Z","shell.execute_reply.started":"2024-12-18T11:35:08.771232Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n        </tr>\n    </thead>\n    <tbody>\n    </tbody>\n</table>","text/plain":"++\n||\n++\n++"},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nDROP TABLE IF EXISTS streaming;"},{"cell_type":"code","execution_count":33,"id":"e9121044-786a-46a9-a583-e7e988e61695","metadata":{"execution":{"iopub.execute_input":"2024-12-18T11:35:15.730703Z","iopub.status.busy":"2024-12-18T11:35:15.729183Z","iopub.status.idle":"2024-12-18T11:35:17.416512Z","shell.execute_reply":"2024-12-18T11:35:17.415856Z","shell.execute_reply.started":"2024-12-18T11:35:15.730296Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n        </tr>\n    </thead>\n    <tbody>\n    </tbody>\n</table>","text/plain":"++\n||\n++\n++"},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nDROP DATABASE IF EXISTS spark_demo;"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"singlestore_cell_default_language":"sql","singlestore_connection":{"connectionID":"a348c3f0-ffc6-458f-94c5-e15b836d9cfa","defaultDatabase":"spark_demo"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}