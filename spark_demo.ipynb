{"cells":[{"attachments":{},"cell_type":"markdown","id":"0cd3122a-d5b8-4ad7-88d4-acb0d297e94a","metadata":{"language":"python"},"source":"<img src = \"https://github.com/VeryFatBoy/notebooks/blob/main/common/images/img_github_singlestore-jupyter_featured_2.png?raw=true\">"},{"attachments":{},"cell_type":"markdown","id":"56477740-ea4f-47ac-a1c3-3cc9ccc08a55","metadata":{"language":"python"},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/browser.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Using Apache Spark with SingleStore Notebooks</h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":7,"id":"8fe3d8c7-739f-418c-9f2b-eab712875a4b","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:08:37.088350Z","iopub.status.busy":"2024-12-18T16:08:37.087318Z","iopub.status.idle":"2024-12-18T16:08:41.007018Z","shell.execute_reply":"2024-12-18T16:08:40.939977Z","shell.execute_reply.started":"2024-12-18T16:08:37.088292Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip cache purge --quiet"},{"cell_type":"code","execution_count":8,"id":"8ab8648b-b68e-4a75-b384-84b3622a3d2a","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:08:46.001620Z","iopub.status.busy":"2024-12-18T16:08:45.999964Z","iopub.status.idle":"2024-12-18T16:09:37.635442Z","shell.execute_reply":"2024-12-18T16:09:37.634602Z","shell.execute_reply.started":"2024-12-18T16:08:46.001581Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Channels:\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - openjdk=8\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.12.14 |       hbcca054_0         153 KB  conda-forge\n    certifi-2024.12.14         |     pyhd8ed1ab_0         158 KB  conda-forge\n    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n    openjdk-8.0.412            |       hd590300_1        88.3 MB  conda-forge\n    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        92.7 MB\n\nThe following NEW packages will be INSTALLED:\n\n  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n  openjdk            conda-forge/linux-64::openjdk-8.0.412-hd590300_1 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.12.14-hbcca054_0 \n  certifi                             2024.2.2-pyhd8ed1ab_0 --> 2024.12.14-pyhd8ed1ab_0 \n  libgcc-ng                               13.2.0-h77fa898_6 --> 14.2.0-h69a702a_1 \n  libgomp                                 13.2.0-h77fa898_6 --> 14.2.0-h77fa898_1 \n  openssl                                  3.3.0-hd590300_0 --> 3.4.0-hb9d3cd8_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n"}],"source":"!conda install -y --quiet -c conda-forge openjdk=8"},{"cell_type":"code","execution_count":10,"id":"759a6a24-cb6e-4186-ba81-f376e8d4966c","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:09:47.485133Z","iopub.status.busy":"2024-12-18T16:09:47.484226Z","iopub.status.idle":"2024-12-18T16:10:32.552110Z","shell.execute_reply":"2024-12-18T16:10:32.543352Z","shell.execute_reply.started":"2024-12-18T16:09:47.485089Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install pyspark --quiet"},{"cell_type":"code","execution_count":11,"id":"285dd44c-4c59-4561-8c61-773edbd824d8","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:10:51.410184Z","iopub.status.busy":"2024-12-18T16:10:51.407400Z","iopub.status.idle":"2024-12-18T16:10:51.639262Z","shell.execute_reply":"2024-12-18T16:10:51.636810Z","shell.execute_reply.started":"2024-12-18T16:10:51.410106Z"},"language":"python","trusted":true},"outputs":[],"source":"import pyspark\nimport sys\n\nfrom pyspark.sql import SparkSession"},{"cell_type":"code","execution_count":12,"id":"bd8419fd-cd96-4744-b512-d6c80c826a6b","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:10:54.817324Z","iopub.status.busy":"2024-12-18T16:10:54.816759Z","iopub.status.idle":"2024-12-18T16:10:57.190351Z","shell.execute_reply":"2024-12-18T16:10:57.187082Z","shell.execute_reply.started":"2024-12-18T16:10:54.817277Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"openjdk version \"1.8.0_412\"\nOpenJDK Runtime Environment (Zulu 8.78.0.19-CA-linux64) (build 1.8.0_412-b08)\nOpenJDK 64-Bit Server VM (Zulu 8.78.0.19-CA-linux64) (build 25.412-b08, mixed mode)\n"}],"source":"!java -version"},{"cell_type":"code","execution_count":14,"id":"5f5892fc-d8b0-4a32-bfaa-153df57ec108","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:11:04.640030Z","iopub.status.busy":"2024-12-18T16:11:04.639172Z","iopub.status.idle":"2024-12-18T16:11:04.655050Z","shell.execute_reply":"2024-12-18T16:11:04.651153Z","shell.execute_reply.started":"2024-12-18T16:11:04.639949Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3.5.3\n"}],"source":"print(pyspark.__version__)"},{"cell_type":"code","execution_count":15,"id":"ea1df563-0b4f-48f8-9951-c8653d8bec6c","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:11:07.765895Z","iopub.status.busy":"2024-12-18T16:11:07.764284Z","iopub.status.idle":"2024-12-18T16:11:07.780613Z","shell.execute_reply":"2024-12-18T16:11:07.773931Z","shell.execute_reply.started":"2024-12-18T16:11:07.765865Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]\n"}],"source":"print(sys.version)"},{"cell_type":"code","execution_count":16,"id":"1e4265c2-f968-4f9b-8a20-6d8da36c16d3","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:11:13.935387Z","iopub.status.busy":"2024-12-18T16:11:13.934917Z","iopub.status.idle":"2024-12-18T16:11:24.637918Z","shell.execute_reply":"2024-12-18T16:11:24.637271Z","shell.execute_reply.started":"2024-12-18T16:11:13.935352Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/12/18 16:11:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"}],"source":"# Create a Spark session\nspark = SparkSession.builder.appName(\"Spark Test\").getOrCreate()"},{"cell_type":"code","execution_count":17,"id":"927db2dd-7746-4cfd-9590-e69c790fb20e","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:12:27.019098Z","iopub.status.busy":"2024-12-18T16:12:27.018697Z","iopub.status.idle":"2024-12-18T16:12:31.389384Z","shell.execute_reply":"2024-12-18T16:12:31.388764Z","shell.execute_reply.started":"2024-12-18T16:12:27.019044Z"},"language":"python","trusted":true},"outputs":[],"source":"# Create a DataFrame\ndata = [(\"Peter\", 27), (\"Paul\", 28), (\"Mary\", 29)]\ndf = spark.createDataFrame(data, [\"Name\", \"Age\"])"},{"cell_type":"code","execution_count":18,"id":"a58a70a7-86bf-44e4-b8fb-1f0838e57929","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:12:33.792101Z","iopub.status.busy":"2024-12-18T16:12:33.791442Z","iopub.status.idle":"2024-12-18T16:12:40.330111Z","shell.execute_reply":"2024-12-18T16:12:40.329275Z","shell.execute_reply.started":"2024-12-18T16:12:33.792020Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"                                                                                \r"},{"name":"stdout","output_type":"stream","text":"+-----+---+\n| Name|Age|\n+-----+---+\n|Peter| 27|\n| Paul| 28|\n| Mary| 29|\n+-----+---+\n\n"}],"source":"# Show the content of the DataFrame\ndf.show()"},{"cell_type":"code","execution_count":19,"id":"d52a9777-83df-4f1d-a325-8f2c39043db4","metadata":{"execution":{"iopub.execute_input":"2024-12-18T16:12:43.359323Z","iopub.status.busy":"2024-12-18T16:12:43.357952Z","iopub.status.idle":"2024-12-18T16:12:44.504895Z","shell.execute_reply":"2024-12-18T16:12:44.504207Z","shell.execute_reply.started":"2024-12-18T16:12:43.359241Z"},"language":"python","trusted":true},"outputs":[],"source":"# Stop the Spark session\nspark.stop()"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"ee3b81d3-c349-4926-bd4b-6784b6bb2d9c","defaultDatabase":""},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}